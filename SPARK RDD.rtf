{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1033{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\*\generator Riched20 10.0.17134}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\f0\fs40\lang22 Li\'e7\'e3o Um: Introdu\'e7\'e3o Este curso foi desenvolvido em colabora\'e7\'e3o com o MetiStream e o IBM Analytics. Esta li\'e7\'e3o \'e9 apenas uma breve introdu\'e7\'e3o sobre dados notebooks para prepar\'e1-lo para os exerc\'edcios de laborat\'f3rio. Depois de completar esta li\'e7\'e3o, voc\'ea deve estar use o zeppelin em seus projetos e identifique os v\'e1rios blocos de anota\'e7\'f5es que voc\'ea pode usar com o Spark. O Apache Zeppelin \'e9 uma ferramenta de an\'e1lise de dados interativa iniciada pela NFLabs. Com o Zeppelin voc\'ea pode executar c\'f3digo e criar visualiza\'e7\'f5es por meio de uma interface da web. Voc\'ea pode conectar virtualmente qualquer linguagem de programa\'e7\'e3o ou backend de processamento de dados. O Zeppelin vem configurado com o Scala e o Spark, al\'e9m do markdown, do Spark SQL e do shell. Voc\'ea pode visitar a p\'e1gina inicial do projeto para mais informa\'e7\'f5es. O Jupyter \'e9 uma evolu\'e7\'e3o do IPython, um notebook maduro baseado em python. IPython ainda \'e9 o O kernel do Python, mas o Jupyter tamb\'e9m suporta outras linguagens, incluindo Julia, Ruby, R e Haskell. Ele suporta o pyspark, a API de igni\'e7\'e3o para python e visualiza\'e7\'f5es usando a biblioteca pyplot. Visite jupyter.org para mais informa\'e7\'f5es. A bancada do cientista de dados \'e9 uma plataforma de dados em desenvolvimento da IBM. \'c9 constru\'eddo em torno de notebooks Jupyter / Ipython. o workbench vem pr\'e9-instalado com Python, Scala e R. Voc\'ea pode colaborar, pesquisar e compartilhar cadernos. Existem muitos tutoriais e cadernos dispon\'edveis, variando de introdut\'f3rio ao uso de bibliotecas avan\'e7adas. Voc\'ea pode se registrar para visualizar o tecnologia em datascientistworkbench.com Outra op\'e7\'e3o \'e9 o notebook Spark, um garfo de O Scala Notebook centrou-se no desenvolvimento do Spark, com suporte integrado ao Spark SQL. Caderno Fa\'edsca permite usar o JavaScript diretamente para criar visualiza\'e7\'f5es. Uma \'faltima solu\'e7\'e3o de notebook \'e9 a nuvem de banco de dados. Atualmente, est\'e1 dispon\'edvel apenas na Amazon Web Services e \'e9 executado na sua conta do EC2. Aqui vemos partes da interface do Zeppelin. Voc\'ea usa tags especiais para identificar qual back-end deve ser usado. O padr\'e3o (sem tags) \'e9 Scala. UMA O SparkContext \'e9 automaticamente instanciado com a vari\'e1vel \ldblquote sc\rdblquote . H\'e1 tamb\'e9m um SQLContextOs tags sql, sh e md especificam SQL, bash shell e markdown, respectivamente. O bot\'e3o play, ou shift-enter para breve, executa o painel. Voc\'ea pode alternar a sa\'edda exibir e alterar as configura\'e7\'f5es do painel tamb\'e9m. Voc\'ea vai se familiarizar com o Zeppelin em os exerc\'edcios de laborat\'f3rio. Tendo completado esta li\'e7\'e3o, voc\'ea deve estar capaz de usar o Zeppelin em seus projetos Spark e identificar os v\'e1rios notebooks que voc\'ea pode use com o Spark. Procedimentos para o exerc\'edcio 1 e a pr\'f3xima li\'e7\'e3o.\par
\fs22\par
Which of the following statements about Zeppelin Notebook is NOT true?\par
\par
 Zeppelin is open-source.  With Zeppelin, you can run code and create visualizations through a web interface.  Zeppelin comes configured with Scala, Spark, and Julia. Zeppelin comes configured with Scala, Spark, and Julia. - correct Zeppelin is an interactive data analytics tool started by NFLabs.\par
 FINAL CHECK YOUR ANSWER  SALVAR YOUR ANSWER Voc\'ea utilizou 1 de 2 envios\par
REVIEW QUESTION 2  (%(num_points) ponto poss\'edvel)\par
Jupyter Notebook and Data Scientist Workbench are both open-source projects. True or false?\par
\par
 False  True True - incorrect\par
Voc\'ea utilizou 1 de 1 envios\par
REVIEW QUESTION 3  (1/1 ponto)\par
Which notebook will you use in the lab section of this course?\par
\par
\b RDD\par
\b0\par
 \fs40 DataBricks  Zeppelin Zeppelin - correct Data Scientist Work Bench  Jupyter Notebookentender o que torna um resiliente RDD, entender como os RDDs s\'e3o divididos em tarefas e est\'e1gios, e serializar tarefas. At\'e9 agora voc\'ea deve estar familiarizado com o resiliente Conjunto de dados distribu\'eddo, a abstra\'e7\'e3o de dados fundamental no Spark. \b Um RDD \'e9 composto por v\'e1rias parti\'e7\'f5es\b0 . \b Spark normalmente determina o n\'famero de parti\'e7\'f5es com base no n\'famero de CPUs no seu cluster.\b0  Cada parti\'e7\'e3o tem uma seq\'fc\'eancia de registros que as tarefas executar\'e3o em. \b O particionamento \'e9 o que permite a execu\'e7\'e3o paralela de trabalhos do Spark. \b0 Lembre-se de que um RDD faz parte de um gr\'e1fico, \'e0s vezes chamado de linhagem, que rastreia hist\'f3ria\b . O Spark usa APIs padr\'e3o do Hadoop para entrada. Por causa disso, \'e9 capaz de ler muitos armazenamentos de dados diferentes, al\'e9m de HDFS, incluindo o sistema de arquivos local e servi\'e7os de nuvem como Cloudant, AWS, Google, e Azure. \b0 Qualquer implementa\'e7\'e3o InputFormat tamb\'e9m pode ser usado diretamente pela API hadoopFile para conex\'e3o com o HBase, o MongoDB, o Cassandra e muito mais.Voc\'ea tamb\'e9m pode implementar seus pr\'f3prios InputFormats, se necess\'e1rio. As parti\'e7\'f5es no RDD mapeiam para as divis\'f5es do Hadoop, conforme definido pelo InputFormat. Isso permite que o Spark aproveite a localidade dos dados quando os n\'f3s do Spark s\'e3o implantados no Hadoop N\'f3s de dados. Voc\'ea tamb\'e9m pode especificar um particionamento m\'ednimo se necess\'e1rio. O particionamento se correlaciona com o paralelismo de tarefas, uma vez que cada tarefa \'e9 executada em uma \'fanica parti\'e7\'e3o de dados. Um elemento-chave do desempenho \'e9 balancear as parti\'e7\'f5es com o n\'famero de n\'facleos no seu grupo. Aqui est\'e1 um exemplo de uso do textFile embutido API. \b Esta \'e9 apenas uma fun\'e7\'e3o de conveni\'eancia que chama a API hadoopFile, da mesma forma que voc\'ea iria ler um arquivo de texto em um programa MapReduce. A API textFile simplesmente chama a fun\'e7\'e3o de mapa descartar a chave e extrair apenas o valor de texto de cada registro (linha de texto) no arquivo. Se olharmos para o gr\'e1fico do RDD completo voc\'ea pode ver que a raiz \'e9 um HadoopRDD e, em seguida, um MappedRDD. Como sabemos, cada RDD em um \b0 grafo tem uma refer\'eancia \'e0s suas depend\'eancias, at\'e9 a raiz RDD, que depende de nada. \'c9 importante saber como isso afeta o particionamento. A raiz RDD descreve o particionamento original. Essas parti\'e7\'f5es s\'e3o herdadas pelos RDDs filhos. As transforma\'e7\'f5es de cada RDD, como no exemplo acima, s\'e3o executadas em cada parti\'e7\'e3o do pai RDD. No entanto, em breve veremos situa\'e7\'f5es em que ocorre um reparticionamento. O particionamento pode ter um enorme impacto no desempenho no Spark. Existem v\'e1rios fatores a serem considere que abordaremos nesta li\'e7\'e3o. Voc\'ea quer que seus dados sejam distribu\'eddos uniformemente atrav\'e9s de parti\'e7\'f5es para alavancar o paralelismo e reduzir a chance de ter um trabalho que leva muito mais tempo que os outros, causando um gargalo.\par
\par
Por padr\'e3o, as parti\'e7\'f5es e os registros dentro deles s\'e3o distribu\'eddos com base no InputFormat do sistema de armazenamento. Por exemplo, no Hadoop, as parti\'e7\'f5es correspondem ao HDFS n\'facleos.\b  Opera\'e7\'f5es de RDD, como filtro e mapa, n\'e3o alterar o particionamento\b0 . No entanto, em alguns casos, voc\'ea pode querer for\'e7ar um aumento ou diminui\'e7\'e3o nas parti\'e7\'f5es. Reparti\'e7\'e3o causar\'e1 um shuffle e redistribuir\'e1 parti\'e7\'f5es uniformemente. Reparti\'e7\'e3o pode ser \'fatil para reequilibrar ap\'f3s filtrar ou reduzir registros e para aumentar o paralelismo se as divis\'f5es de entrada forem muito baixas para seu cluster. \b Coalesce pode diminuir parti\'e7\'f5es sem incorrer em um shuffle. \b0 Coalesce \'e9 \'fatil quando voc\'ea quer consolidar parti\'e7\'f5es antes de enviar para o HDFS ou sistemas externos, mas voc\'ea perde o paralelismo.Quando codificamos um RDD, seja por um mapa ou usando o keyBy, n\'e3o estamos alterando o particionamento. Tudo o que fizemos foi mapear cada valor para ter uma chave. Essas chaves podem ou n\'e3o estar localizadas e n\'e3o temos como saber, pois normalmente um RDD n\'e3o ter\'e1 um particionador quando ele primeiro gerado. No entanto, para determinadas opera\'e7\'f5es com chave ou processamento iterativo, \'c9 ben\'e9fico manter registros com as mesmas chaves co-localizadas. Isso permite nossas transforma\'e7\'f5es executar rapidamente dentro da mesma JVM ao operar sobre as mesmas chaves. Para fazer isso n\'f3s pode usar um HashPartitioner ou RangePartitioner. No caso do HashPartitioner, especificamos o n\'famero de parti\'e7\'f5es e vai garantir que todas as chaves com o mesmo hash estar\'e3o em a mesma parti\'e7\'e3o. Isso N\'c3O significa que cada chave ter\'e1 sua pr\'f3pria parti\'e7\'e3o. Isso \'e9 chamado hashing consistente, onde o m\'f3dulo hash de chave o n\'famero de parti\'e7\'f5es define a parti\'e7\'e3o em que o registro ser\'e1 colocado. A chamada de partitionBy ir\'e1 sofrer um shuffle mas a jusante opera\'e7\'f5es se beneficiar\'e3o dos registros co-localizados.\par
\b Considere um RDD com 3 parti\'e7\'f5es e nenhum particionador. \b0 As chaves n\'e3o est\'e3o colocadas. Se n\'f3s planejamos fazendo opera\'e7\'f5es com chave, seria melhor reparticionar para que todos os valores para o mesma chave est\'e3o na mesma parti\'e7\'e3o. Simplesmente chame o partitionby com um particionador hash com o n\'famero desejado de parti\'e7\'f5es. Um shuffle ir\'e1 ocorrer, mas outras opera\'e7\'f5es ser mais eficiente. Juntando RDDs que n\'e3o possuem particionador fazer com que cada executor embaralhe todos os valores com a mesma chave para uma \'fanica m\'e1quina, para ambos os RDDs. Se voc\'ea est\'e1 participando repetidamente do mesmo RDD, isso \'e9 altamente ineficiente. O RDD resultante usar\'e1 um HashPartitioner com o n\'famero de parti\'e7\'f5es igual ao maior RDD. Se voc\'ea precisar participar de um RDD v\'e1rias vezes, A melhor op\'e7\'e3o \'e9 particion\'e1-lo. Neste caso, apenas o RDD "direito" ser\'e1 embaralhado atrav\'e9s da rede para a parti\'e7\'e3o correspondente do RDD "esquerdo". Na melhor das hip\'f3teses, os RDDs esquerdo e direito s\'e3o \ldblquote co-particionados\rdblquote , ent\'e3o eles t\'eam chaves semelhantes e o mesmo particionador e o mesmo n\'famero de parti\'e7\'f5es. Enquanto um shuffle ainda ocorrer\'e1, se as parti\'e7\'f5es de diferentes RDDs estiverem no mesmo executor, elas n\'e3o ser\'e3o atravessar a rede. Em geral, isso gerar\'e1 a menor quantidade de I / O de rede e lat\'eancia. RDD de resili\'eancia descreve uma linhagem de transforma\'e7\'f5es que s\'e3o executados pregui\'e7osamente. Como vimos, cada RDD depende do pai. Descreve alguma transforma\'e7\'e3o para executar cada parti\'e7\'e3o do RDD pai. Manter essa linhagem nos permite reconstruir os resultados no caso de uma falha. assim se uma parti\'e7\'e3o for perdida em um executor, o Spark s\'f3 precisar\'e1 recompurar essas parti\'e7\'f5es perdidas subindo a \'e1rvore de linhagem at\'e9 atingir uma raiz ou RDD persistente. Por exemplo, digamos que temos dois RDDs que est\'e3o juntos. Em seguida, persistimos o RDD na mem\'f3ria. Durante as pr\'f3ximas opera\'e7\'f5es, um reduceByKey e saveAsTextFile, ocorre uma falha e uma das parti\'e7\'f5es \'e9 perdida. Spark \'e9 capaz de percorrer a linhagem RDD at\'e9 encontrar o \'faltimo estado bom conhecido. Em seguida, ele pode recomputar a parti\'e7\'e3o perdida. Observe que n\'e3o \'e9 necess\'e1rio recomputar todos os parti\'e7\'e3o, apenas o que foi perdido. Executando trabalhos A\'e7\'f5es de fa\'edsca podem ser pensadas em tr\'eas etapas. Um Job \'e9 uma sequ\'eancia de transforma\'e7\'f5es iniciada por uma a\'e7\'e3o, como coletar, reduzir, etc. Os trabalhos s\'e3o divididos em etapas, que em por sua vez, consistem em tarefas. O agendador analisa toda a linhagem RDD e determina como dividir o trabalho em etapas e tarefas. Os limites dos est\'e1gios s\'e3o definidos por depend\'eancias aleat\'f3rias, ou seja, quando uma jun\'e7\'e3o, reparti\'e7\'e3o ou outra opera\'e7\'e3o Isso faz com que um shuffle ocorra. Transforma\'e7\'f5es que causam um shuffle tamb\'e9m s\'e3o chamadas depend\'eancias. As tarefas s\'e3o ent\'e3o serializadas e distribu\'eddas aos executores. Tarefas s\'e3o as opera\'e7\'f5es que definimos nosso programa Driver para esse RDD. Os encerramentos (AKA lambdas) que escrevemos em nosso c\'f3digo receber\'e3o serializado, em seguida, implantado para cada executor com a parti\'e7\'e3o em que essa tarefa deve executar. O importante a lembrar aqui \'e9 o fato de que as tarefas devem ser serializ\'e1veis, uma vez que elas precisam ser enviadas pela rede para os n\'f3s do trabalhador. Isso inclui as tarefas em si, bem como quaisquer refer\'eancias que fazer para objetos e vari\'e1veis \u8203?\u8203?dentro do driver. Voc\'ea tem que ter cuidado para que suas tarefas n\'e3o sejam muito grande, por exemplo, com grandes vari\'e1veis \u8203?\u8203?locais (como cole\'e7\'f5es ou mapas). Existem m\'faltiplos custos associados a grandes tarefas. O primeiro \'e9 serializa\'e7\'e3o e desserializa\'e7\'e3o custo. Al\'e9m disso, h\'e1 a E / S da rede para enviar essas tarefas toda vez que a transforma\'e7\'e3o \'c9 executado. Finalmente grandes tarefas podem atrasar o tempo de execu\'e7\'e3o das tarefas.\par
Alguns erros comuns que voc\'ea pode obter, especialmente ao criar aplicativos mais complexos usando Bibliotecas de terceiros, s\'e3o erros de \ldblquote tarefa n\'e3o serializ\'e1vel\rdblquote . Estes tipicamente surgem em complexos tarefas referenciando vari\'e1veis \u8203?\u8203?de membros da classe que definem os fechamentos. Neste exemplo, temos uma classe auxiliar muito b\'e1sica que realmente n\'e3o faz muito. N\'f3s refer\'eancia em uma opera\'e7\'e3o de mapa. Se tentarmos executar uma a\'e7\'e3o no RDD de sa\'edda, receberemos um erro. O problema \'e9 que o "MyHelper" n\'e3o implementa Serializable. Ent\'e3o, se estendemos nossa classe com Serializable e tente execut\'e1-lo novamente funcionar\'e1 corretamente. E se "MyHelper", por sua vez, tamb\'e9m estiver fazendo refer\'eancia a outra biblioteca de terceiros como uma vari\'e1vel de membro qual n\'e3o \'e9 serializ\'e1vel? Podemos n\'e3o querer (ou ser capazes de) alterar o c\'f3digo para torn\'e1-lo serializ\'e1vel. Al\'e9m disso, por causa do custo de envio de objetos grandes como parte do nosso seria seja melhor n\'e3o serializar todo o gr\'e1fico de objetos. Que outra op\'e7\'e3o n\'f3s temos? Se marcarmos a vari\'e1vel de membro transit\'f3ria e pregui\'e7oso, ele n\'e3o ser\'e1 serializado, mas ainda ser\'e1 instanciado localmente em cada tarefa e nosso c\'f3digo ser\'e1 executado como esperado, sem incorrer no custo de serializar um grande tarefa ou muitas altera\'e7\'f5es de c\'f3digo. Aqui temos outro exemplo, desta vez de um aplicativo Scala completo. Temos uma classe local \ldblquote MyOtherHelper\rdblquote  usada em uma opera\'e7\'e3o de mapa. Na sua forma atual Esse exemplo falhar\'e1, mesmo que a classe auxiliar seja serializ\'e1vel. Por qu\'ea? Porque "helper1" \'e9 uma vari\'e1vel de membro do MySparkApp, e, assim, o Spark tenta serializar essa inst\'e2ncia tamb\'e9m. N\'f3s apenas poder\'edamos tornar o MySparkApp serializ\'e1vel, mas \'e9 realmente uma boa ideia enviar nosso app para cada trabalhador? A melhor op\'e7\'e3o \'e9 fazer uma refer\'eancia local para "helper1". Desta forma, estamos mantendo nossa tarefa o mais magra poss\'edvel, minimizando problemas de serializa\'e7\'e3o em gr\'e1ficos de objetos grandes. Como discutimos anteriormente, os est\'e1gios s\'e3o definidos por depend\'eancias aleat\'f3rias. Aqui temos um gr\'e1fico de 2 RDDs sendo unidos, depois um reduceByKey e finalmente um saveAsTextFile. Aqui est\'e1 a linhagem RDD de chamar para depurar corda. A cadeia de depura\'e7\'e3o destaca claramente o est\'e1gio limites. O est\'e1gio um e dois s\'e3o os RDDs originais sendo filtrada, mapeada e digitada em prepara\'e7\'e3o para a jun\'e7\'e3o. A jun\'e7\'e3o requer um shuffle, ent\'e3o h\'e1 um limite de est\'e1gio l\'e1. O terceiro est\'e1gio \'e9 o reduza e salve ap\'f3s a jun\'e7\'e3o. Spark tem um destaque chamado execu\'e7\'e3o especulativa para lidar com tarefas lentas. Conforme os est\'e1gios est\'e3o sendo executados, tarefas lentas ser\'e3o relan\'e7adas como necess\'e1rio. A execu\'e7\'e3o especulativa est\'e1 desativada por padr\'e3o. Podemos ativ\'e1-lo definindo o par\'e2metro spark.speculation como true. \ldblquote Slow\rdblquote  \'e9 um valor configur\'e1vel definido por spark.speculation.multiplier. Isso define quantas vezes uma tarefa \'e9 mais lenta que a mediana a ser considerada para especula\'e7\'e3o. Tamb\'e9m precisamos de uma maneira de lidar com tarefas com falha. Tarefas podem falhar devido a problemas de mem\'f3ria, problemas de hardware subjacentes, problemas de rede, etc. Por padr\'e3o, o Spark tentar\'e1 uma tarefa 3 vezes antes de falhar um est\'e1gio, que pode ser alterado com o par\'e2metro spark.task.maxFailures conforme necess\'e1rio.\par
Por exemplo, voc\'ea pode querer falhar r\'e1pido versus executar uma tarefa longa v\'e1rias vezes para encontrar h\'e1 um problema no seu cluster. Uma quest\'e3o importante a ter em conta \'e9 qualquer opera\'e7\'e3o que tem efeitos colaterais, como a sa\'edda de dados em um para cada chamada. Se a nossa tarefa falhar e for executada novamente, pode muito bem tentar reproduzir esses dados novamente. Se voc\'ea estiver usando um c\'f3digo personalizado para escrever para outro sistema, saiba que voc\'ea pode precisar para garantir que a opera\'e7\'e3o seja idempotente. A maior parte do que vimos at\'e9 agora um usu\'e1rio \'fanico trabalhando no shell do Spark ou um \'fanico aplicativo sendo enviado trabalhando em um tarefa \'fanica. Por padr\'e3o, o Spark usa um agendador FIFO b\'e1sico. Funciona bem para usu\'e1rio \'fanico aplicativos em que cada trabalho recebe tantos recursos de que precisa. O SparkContext \'e9 totalmente seguro para thread, por isso, dentro de um aplicativo Spark, podemos realmente enviar trabalhos de v\'e1rios segmentos. Se v\'e1rios trabalhos forem enviados simultaneamente, eles poder\'e3o ser executados em paralelo se o primeiro trabalho n\'e3o precisa de todos os recursos do cluster. No entanto, se esse n\'e3o for o caso, voc\'ea pode ter um \'fanico trabalho grande que faz o backup de todos outros pedidos at\'e9 terminar. Para ambientes multiusu\'e1rios, como o Zeppelin, voc\'ea desejar\'e1 usar o Fair scheduler, que pode ser configurado com o par\'e2metro spark.schedule.mode. Por padr\'e3o, o planejador justo divide os recursos do cluster de maneira round-robin, dando partes iguais de recursos. Ent\'e3o, mesmo que voc\'ea tenha um trabalho muito grande, n\'e3o vai parar um pequeno e curto trabalho de come\'e7ar e correr. Podemos tamb\'e9m definir pools, que possuem atributos como pesos e compartilhamentos m\'ednimos dos recursos do cluster. As piscinas podem ter seu pr\'f3prio agendador. Pools s\'e3o \'fateis para definir filas de prioridade (como para um determinado usu\'e1rio ou grupo) ou dando a cada usu\'e1rio um pool que \'e9 internamente apenas uma fila FIFO. Este \'e9 o modelo que o Zeppelin usa para permitir que v\'e1rios usu\'e1rios trabalhem Cluster Spark ao mesmo tempo. A configura\'e7\'e3o de pools do Fair Scheduler customizados envolve primeiro definindo um arquivo XML com os pools e suas propriedades de configura\'e7\'e3o. Ent\'e3o no seu Aplicativo Spark ou configura\'e7\'f5es de configura\'e7\'e3o, voc\'ea precisa definir a configura\'e7\'e3o spark.scheduler.allocation.file, apontando para esse arquivo XML. Enviar um trabalho para um pool espec\'edfico \'e9 feito definindo uma propriedade local no SparkContext, spark.scheduler.pool. Este \'e9 um segmento local propriedade por isso, se voc\'ea gerar v\'e1rios segmentos em seu driver cada um ter\'e1 que definir este valor. Para limpar o valor, basta defini-lo como nulo. Tendo completado esta li\'e7\'e3o, voc\'ea deve ser capaz de entender como o Spark gera RDDs, gerenciar parti\'e7\'f5es para melhorar o desempenho do RDD, entender o que torna um RDD resiliente, entender como os RDDs s\'e3o divididos em tarefas e est\'e1gios e serializam tarefas. Prossiga para o exerc\'edcio 2 e a pr\'f3xima li\'e7\'e3o.\par
\par
Partitioning is what enables parallel execution of Spark jobs. \b TRUE\par
\b0 An RDD is made up of multiple partitions. \b TRUE\par
\b0 Spark is able to read from many different data stores in addition to HDFS, including the local file system and cloud services like Cloudant, AWS, Google, and Azure. \b TRUE\par
\b0 Spark normally determines the number of partitions based on the size of the hard drives in your cluster. Spark normally determines the number of partitions based on the size of the hard drives in your cluster. - correct\b - FALSE\par
\b0 Speculative execution handles slow tasks by re-launching them as necessary. True or false? \b TRUE\par
\par
Acoes e transformacoes\par
\par
\b0 Li\'e7\'e3o 3: Otimizando Transforma\'e7\'f5es e A\'e7\'f5es Este curso foi desenvolvido em colabora\'e7\'e3o com o \b MetiStream\b0  e o \b IBm Analytics\b0 . Depois de completar esta li\'e7\'e3o, voc\'ea deve estar capaz de usar opera\'e7\'f5es avan\'e7adas de RDD, identificar quais opera\'e7\'f5es causam embaralhamento, entender como evitar embaralhar quando poss\'edvel e agrupar, combinar e reduzir pares de valores-chave. Come\'e7aremos analisando algumas das opera\'e7\'f5es de RDD mais avan\'e7adas dispon\'edveis. \b RDDs num\'e9ricos t\'eam v\'e1rias opera\'e7\'f5es estat\'edsticas que podem ser calculadas como desvio padr\'e3o, soma, m\'e9dia, max, min, etc. \b0 Voc\'ea pode calcular uma opera\'e7\'e3o espec\'edfica ou chamar stats () para retornar um objeto com acesso a todos os valores. as parti\'e7\'f5es de mapa s\'e3o como o mapa normal, exceto a fun\'e7\'e3o est\'e1 no n\'edvel da \b parti\'e7\'e3o\b0 . Assim, cada conjunto de valores em uma parti\'e7\'e3o \'e9 mapeado para zero ou mais valores. Um caso em que essas opera\'e7\'f5es s\'e3o particularmente \'fateis \'e9 quando sua fun\'e7\'e3o de mapa tem um alto custo indireto por registro. Por exemplo, se voc\'ea precisar se conectar para um banco de dados, voc\'ea poderia fazer isso uma vez por parti\'e7\'e3o em vez de cada registro individual. mapPartitionsWithIndex simplesmente adiciona o \'edndice da parti\'e7\'e3o como um par\'e2metro foreachPartition - executa uma a\'e7\'e3o que se repete sobre cada parti\'e7\'e3o. Voc\'ea quer usar isso para opera\'e7\'f5es em lote, como envio a um servi\'e7o da Web ou envio para dados externos fontes. Voc\'ea gostaria de fazer isso em vez de fazer uma chamada para cada um, que itera sobre cada indiv\'edduo registro. Existem v\'e1rias opera\'e7\'f5es que podem ser usado em conjuntos de dados extremamente grandes para obter valores aproximados. Por exemplo, \b countApproxDistinct ir\'e1 aproximar o n\'famero de valores distintos dentro do desvio padr\'e3o dado.\par
\par
\b0 A dobra \'e9 um caso especial de redu\'e7\'e3o. Voc\'ea passa um acumulador zero inicial e uma fun\'e7\'e3o. A fun\'e7\'e3o \'e9 uma opera\'e7\'e3o seq\'fcencial ou comparativa entre o elemento RDD e o acumulador, retornando o acumulador final. Agregar \'e9 semelhante a dobrar, mas leva dois fun\'e7\'f5es. O primeiro \'e9 executado em cada parti\'e7\'e3o. O segundo combina os resultados de cada parti\'e7\'e3o acumulador. \b countByValue \'e9 apenas um m\'e9todo de conveni\'eancia que conta o n\'famero de ocorr\'eancias de cada valor e as coleta em um mapa\b0 . Internamente est\'e1 mapeando para um par RDD e chamando countByKey. Podemos ver como funciona revisitando nossa exemplo de contagem de palavras. A segunda e terceira linhas s\'e3o opera\'e7\'f5es id\'eanticas. Algumas opera\'e7\'f5es s\'f3 podem ser realizadas em RDDs de valor-chave. Reduzir pela chave executa uma redu\'e7\'e3o em todos os valores de uma chave e, em seguida, combina os resultados para cada chave em cada parti\'e7\'e3o. Contar por chave \'e9 simplesmente chamar reduceByKey, mas a diferen\'e7a \'e9 que ele coleta os resultados em um mapa que \'e9 enviado de volta para o motorista. Como tal, voc\'ea precisa ter cuidado com esta a\'e7\'e3o - \'e9 mais \'fatil como um simples maneira de examinar seus dados e n\'e3o algo que voc\'ea deseja usar na produ\'e7\'e3o. Agregar e dobrar por chave s\'e3o an\'e1logos aos seus equivalentes gen\'e9ricos, exceto que eles executar por chave. Vamos ver um exemplo em breve. Agrupar por grupos de chaves todos os valores por chave, de TODAS as parti\'e7\'f5es, na mem\'f3ria. Esta a\'e7\'e3o deve acionar os sinos de aviso sempre que voc\'ea v\'ea em um aplicativo Spark. \b Lembre-se que um dos piores culpados de mau desempenho Spark est\'e1 embaralhando\b0 . \b groupbyKey embaralha tudo\b0 . \b Pode at\'e9 causar erros de falta de mem\'f3ria com grandes conjuntos de dados. evite usar sempre que poss\'edvel. \b0 Lookup retorna todos os valores para o especificado chave. \b MapValues \u8203?\u8203?aplica uma fun\'e7\'e3o de mapa para cada valor sem mudar suas chaves. \b0 Quando voc\'ea usa isso em vez de um mapa comum, o Spark sabe que qualquer particionamento anterior ainda \'e9 v\'e1lido e, portanto, \b o reparticionamento n\'e3o \'e9 necess\'e1rio.\b0  Finalmente, reparticionar e ordenar dentro de parti\'e7\'f5es faz uma reparti\'e7\'e3o e ordenar por chave all in Um passo, que \'e9 mais eficiente do que chamar classificar por tecla ap\'f3s uma reparti\'e7\'e3o.\par
\par
\par
Neste exemplo, veremos como as fun\'e7\'f5es agregadas s\'e3o usadas e por que grupos por a chave deve ser evitada. Considere o seguinte caso de uso: queremos calcular a m\'e9dia valor para cada chave em um RDD. Isso poderia ser feito facilmente com grupo por chave. Basta ligar para o grupo por chave, localize a m\'e9dia de cada chave dividindo a soma pelo n\'famero de elementos. Uma maneira melhor de fazer isso \'e9 agregada por chave. Vamos percorrer o c\'f3digo. A inicial acumulador de valor zero \'e9 apenas 0, 0; uma soma de zero para valores totais zero. A primeira fun\'e7\'e3o itera todos os valores de uma determinada chave, adicionando-os \'e0 soma e aumentando a contagem de o acumulador para essa chave por um. Ent\'e3o a segunda fun\'e7\'e3o combina os acumuladores\par
para uma determinada chave de cada parti\'e7\'e3o. Finalmente, chamamos mapValues \u8203?\u8203?da mesma maneira que antes para calcular a m\'e9dia por chave. Este diagrama mostra o que acontece usando groupByKey. \b groupByKey causa um shuffle de TODOS os valores na rede,\b0  mesmo que eles j\'e1 estejam co-localizado dentro de uma parti\'e7\'e3o e, em seguida\b , calcula a m\'e9dia por chave\b0 . Al\'e9m do custo de E / S de rede, voc\'ea tamb\'e9m est\'e1 usando muito \b mais mem\'f3ria\b0 . Em contraste, o uso de \b aggregateByKey divide o c\'e1lculo em duas etapas. Apenas um par por chave, por parti\'e7\'e3o \'e9 embaralhada, reduzindo bastante a E / S e o uso da mem\'f3ria\b0 . Ent\'e3o os resultados de cada parti\'e7\'e3o s\'e3o combinados. Outro exemplo seria obter o primeiro valor de uma sequ\'eancia para cada chave. Novamente aqui voc\'ea pode ser tentado a apenas groupByKey ent\'e3o execute um map / mapValues \u8203?\u8203?e para cada grupo, basta pegar o elemento head. O problema mais uma vez \'e9 o impacto na mem\'f3ria que isso ter\'e1 com grandes conjuntos de dados. \b Uma solu\'e7\'e3o melhor \'e9 usar reduceByKey.\b0\'c0 medida que cada par de valores \'e9 passado, voc\'ea pode compar\'e1-los e escolher qual registro manter. Isso ser\'e1 executado com efici\'eancia em todas as chaves em cada parti\'e7\'e3o sem incorrer em sobrecarga de mem\'f3ria grande. A\'e7\'f5es est\'e3o bloqueando opera\'e7\'f5es. Isso \'e9, enquanto as transforma\'e7\'f5es s\'e3o \b executadas pregui\'e7osamente\b0 , uma vez que voc\'ea chama \b uma a\'e7\'e3o como contar, coletar, para cada um, etc. \b0 seu motorista tem que esperar que ele termine. Voc\'ea pode contornar isso com opera\'e7\'f5es \b ass\'edncronas. \b0 Estes s\'e3o implementados como futuros, para que voc\'ea possa definir uma fun\'e7\'e3o de retorno de chamada para executar depois de conclu\'eddas. As a\'e7\'f5es b\'e1sicas fornecem vers\'f5es ass\'edncronas correspondentes. Voc\'ea precisa estar ciente de que, se planeja executar v\'e1rias opera\'e7\'f5es ass\'edncronas, usando o agendador de tarefas FIFO padr\'e3o eles ainda ser\'e3o conclu\'eddos em s\'e9rie. Voc\'ea ter\'e1 para usar o agendador \b FAIR para calcular as a\'e7\'f5es em paralelo.\b0  Entender o efeito de certas opera\'e7\'f5es no particionamento desempenha um grande papel na otimiza\'e7\'e3o transforma\'e7\'f5es. Por exemplo, digamos que temos um par RDD que j\'e1 \'e9 particionado por hash por 2 parti\'e7\'f5es. Se executarmos uma opera\'e7\'e3o de mapa sobre todos os registros, poderemos potencialmente transformar as chaves de cada registro. Por causa disso, Spark n\'e3o tem como saber se o particionado as chaves corresponder\'e3o no outro lado da opera\'e7\'e3o do mapa. Neste caso, o RDD resultante...\par
na verdade n\'e3o ter\'e1 mais um particionador. Isso significa que mesmo que n\'e3o alteremos as chaves e eles permanecem dentro das parti\'e7\'f5es originais, quando executamos \b um reduceByKey\b0 , um shuffle completo \'e9 vai ocorrer. Se voc\'ea s\'f3 precisa operar nos valores de cada chave / par, sempre use mapValues. Isso informa ao Spark que as chaves com hash permanecer\'e3o em suas parti\'e7\'f5es e podemos manter o mesmo particionador entre as opera\'e7\'f5es. O resultado O reduceByKey agora estar\'e1 ciente do particionamento das chaves. Quando chegar a hora de enviar os dados do seu trabalho Spark, voc\'ea deve usar o padr\'e3o APIs sempre que poss\'edvel. No entanto, em alguns casos, voc\'ea pode ter l\'f3gica ou sistemas personalizados do que o HDFS com o qual voc\'ea precisa se integrar. \'c9 importante entender o impacto de usar foreach versus foreachPartition. \b foreach executar\'e1 seu fechamento para cada registro individualmente.\b0  Isso obviamente n\'e3o \'e9 eficiente ao lidar com grandes volumes. \b foreachPartition \'e9 mais apropriado.\b0  Seu encerramento ser\'e1 executado em paralelo em cada parti\'e7\'e3o recebendo um Iterator para todos os registros dentro dessa parti\'e7\'e3o. \b Se voc\'ea precisar salvar em um ODBC padr\'e3o ou O banco de dados JDBC considera o uso do Hadoop DBOutputFormat junto com o SparkContext saveAsHadoopDataset API. \b0 Voc\'ea precisa ter cuidado com o n\'edvel de paralelismo e volume de dados para que voc\'ea n\'e3o sobrecarrega seu banco de dados. Para qualquer sa\'edda personalizada, como envio para filas de mensagens ou pontos de extremidade REST, em seguida, use definitivamente foreachPartition. Lembre-se de estar ciente de quaisquer problemas de serializa\'e7\'e3o. Pode ser melhor apenas inicializar conex\'f5es dentro do fechamento, em seguida, enviar tudo como uma mensagem grande As vari\'e1veis \u8203?\u8203?de transmiss\'e3o permitem que o programa do driver envie um valor somente leitura a todos os executores referenciar. \b A vari\'e1vel de transmiss\'e3o pode ent\'e3o ser pesquisada por qualquer opera\'e7\'e3o de RDD. Isso pode muitas vezes ser usado para evitar o embaralhamento...\par
O Spark usa um protocolo BitTorrent que fornece compartilhamento peer-to-peer da vari\'e1vel de broadcast entre n\'f3s. Isso melhora o rendimento da rede e reduz a carga no driver\b0 . Voc\'ea pode ficar tentado a apenas passar seus dados como um fechamento de vari\'e1vel local. O problema aqui \'e9 que voc\'ea ter\'e1 que serializar, depois transmitir todo o fechamento serializado para cada n\'f3 executando essa tarefa. Isso atrasaria muito inicializa\'e7\'e3o e desperd\'edcio de espa\'e7o atrav\'e9s da duplica\'e7\'e3o em todos os n\'f3s. Aqui est\'e1 um exemplo usando as viagens e esta\'e7\'f5es dos exerc\'edcios de laborat\'f3rio. Normalmente, juntando as viagens de in\'edcio e fim \'e0s esta\'e7\'f5es exigiriam tr\'eas embaralhamentos: um para reparti\'e7\'e3o, e um para cada jun\'e7\'e3o. Ao transmitir as esta\'e7\'f5es, voc\'ea pode evitar embaralhar completamente com algumas opera\'e7\'f5es de mapa. Analisaremos isso em detalhes no pr\'f3ximo laborat\'f3rio. Tendo esta li\'e7\'e3o, voc\'ea deve ser capaz de entender as opera\'e7\'f5es avan\'e7adas de RDD, identificar que opera\'e7\'f5es causam embaralhamento, entenda como evitar embaralhar quando poss\'edvel e trabalhe com pares de valores-chave agrupando, combinando e reduzindo. Prossiga para o exerc\'edcio 3 e pr\'f3xima li\'e7\'e3o...\par
\par
Saque e Serializa\'e7\'e3o \par
Saque e Serializa\'e7\'e3o Este curso foi desenvolvido em colabora\'e7\'e3o com o MetiStream e o IBM Analytics. Depois de concluir esta li\'e7\'e3o, voc\'ea deve ser capaz de entender como e quando armazenar os RDDs em cache, entender os n\'edveis de armazenamento e seus usos, otimizar o uso de mem\'f3ria com op\'e7\'f5es de serializa\'e7\'e3o, e compartilhe RDDs com o Tachyon\b . O Spark \'e9 muito adequado para a an\'e1lise iterativa por causa de como ele distribui e executa tarefas em todo o cluster e o fato de que ele minimiza a E / S de disco em compara\'e7\'e3o com as estruturas como o MapReduce.\b0  No entanto, \'e0s vezes podemos precisar de alguns ganhos adicionais de desempenho enquanto lidar com o mesmo RDD em v\'e1rias itera\'e7\'f5es. O que \'e9 mais conhecido por Spark \'e9 o uso de cache de mem\'f3ria. \'c9 importante entender quando e como devemos persistir nos RDDs. Persist\'eancia n\'e3o precisa necessariamente estar apenas na mem\'f3ria. Podemos usar uma combina\'e7\'e3o se soubermos...\par
os dados s\'e3o muito grandes para caber na mem\'f3ria ou podemos optar por salvar totalmente no disco se estamos mais preocupados em perder resultados de uma opera\'e7\'e3o cara. Persistindo em disco nos permitiria reconstituir o RDD do disco no caso de uma parti\'e7\'e3o ser perdida, de recontar todas as opera\'e7\'f5es caras para as parti\'e7\'f5es perdidas. O ideal \'e9 que voc\'ea deseje persistir ap\'f3s qualquer remo\'e7\'e3o, filtragem e outras transforma\'e7\'f5es necess\'e1rias para processamento a jusante. Um exemplo \'e9 carregar um arquivo, analis\'e1-lo e particion\'e1-lo por uma chave. \b N\'e3o seria muito bom simplesmente armazenar em cache o RDD raiz se tiv\'e9ssemos que incorrer o filtro, mapear e embaralhar novamente cada vez que reutilizarmos esse RDD\b0 . Em vez disso, ser\'edamos melhores off cache ap\'f3s o partitionBy. \b Quando voc\'ea n\'e3o precisa mais do RDD persistido basta chamar un-persist. \i O Spark tamb\'e9m usar\'e1 um algoritmo menos utilizado recentemente (LRU) conforme necess\'e1rio para abrir espa\'e7o para novos RDDs. Nesta linhagem RDD, estamos nos unindo a dois RDDs aquele que \'e9 filtrado.\b0\i0  Em seguida, temos duas opera\'e7\'f5es de ramifica\'e7\'e3o: uma reduceByKey e um mapValues.\par
\b Seria uma boa id\'e9ia persistir ap\'f3s a associa\'e7\'e3o, quando o RDD estiver preparado e pronto para as a\'e7\'f5es de redu\'e7\'e3o e mapeamento a jusante. Estes s\'e3o os diferentes n\'edveis de armazenamento dispon\'edveis, do guia de programa\'e7\'e3o do Apache Spark. MEMORY_ONLY \'e9 o padr\'e3o. Voc\'ea pode chamar a taquigrafia fun\'e7\'e3o de cache para persistir com o padr\'e3o. Observe como os diferentes n\'edveis lidam com estouro...\par
Com mem\'f3ria apenas, se todo o RDD n\'e3o couber na mem\'f3ria, \b0 algumas das parti\'e7\'f5es ter\'e3o ser recomputado um a mosca. As op\'e7\'f5es DISK gravam o estouro no disco. Voc\'ea tamb\'e9m pode replicar parti\'e7\'f5es persistentes ou armazen\'e1-las em Tachyon, uma maneira de "compartilhar" RDDs sobre os quais falaremos em breve. Enquanto persistir RDDs pode nos ajudar a economizar tempo re-computa\'e7\'e3o de parti\'e7\'f5es, ela tem um custo. Esse \'e9 o espa\'e7o necess\'e1rio para manter tudo esses objetos na mem\'f3ria. \b Manter registros na mem\'f3ria em um \b0 estado bruto ocupa o m\'e1ximo de espa\'e7o...\par
Para ajudar a economizar espa\'e7o, podemos serializar. Os registros de um RDD ser\'e3o armazenados como um grande matriz de bytes. Voc\'ea incorrer\'e1 em algum uso da CPU para desserializar os dados. No entanto, tem o benef\'edcio adicional de ajudar na coleta de lixo, pois voc\'ea armazenar\'e1 1 objeto (o byte array) versus muitos objetos pequenos para cada registro. \b O serializador padr\'e3o \'e9 o serializador Java ou o pickle se voc\'ea estiver usando python. \b0 Outra op\'e7\'e3o para usu\'e1rios de Java e Scala \'e9 o serializador Kryo, que \'e9 mais eficiente ao custo de alguns poss\'edveis problemas de compatibilidade ou configura\'e7\'e3o. Voc\'ea tamb\'e9m pode compactar RDDs serializados na mem\'f3ria com o custo de descompactar Como regra geral, otimize o armazenamento usando tipos primitivos em vez de cole\'e7\'f5es Java ou Scala. Al\'e9m disso, tente evitar classes aninhadas com muitos objetos pequenos, pois isso causar\'e1 grande quantidade de lixo. sobrecarga de cole\'e7\'e3o...\par
Veja um exemplo das viagens e esta\'e7\'f5es que os RDDs est\'e3o usando nos laborat\'f3rios, em cache ambos com e sem serializa\'e7\'e3o. Enquanto o arquivo de entrada n\'e3o comprimido foi de aproximadamente \b 36MB\b0 , o conjunto de dados persistente \'e9 muito maior devido ao tamanho dos objetos Java na mem\'f3ria. Em contraste, a vers\'e3o serializada, usando o serializador Java padr\'e3o, usa apenas 52 MB do espa\'e7o. \b O serializador Kryo realmente consegue armazenar o RDD inteiro em menos espa\'e7o que o arquivo original!\par
\b0 Kryo \'e9 geralmente muito simples de configurar. Aqui vemos como configurar o Kryo para o exerc\'edcios de laborat\'f3rio. Primeiro voc\'ea cria uma nova configura\'e7\'e3o do SparkConf para o aplicativo. Em seguida, voc\'ea configura o par\'e2metro do serializador de igni\'e7\'e3o para o KryoSerializer. Voc\'ea deve ent\'e3o registre as classes em sua aplica\'e7\'e3o que ser\'e3o serializadas, neste caso, o Trip e classes de esta\'e7\'e3o. Finalmente voc\'ea inicializa o contexto da centelha com a configura\'e7\'e3o. Agora, quando voc\'ea usa um n\'edvel de persist\'eancia, como MEMORY_ONLY_SER a serializa\'e7\'e3o ser\'e1 tratada por Kryo\b . Uma pergunta comum quando as pessoas come\'e7am a trabalhar com o Spark \'e9 se os RDDs podem ser compartilhados entre aplicativos. \b0 Como os RDDs est\'e3o vinculados a um SparkContext, isso n\'e3o \'e9 convencional poss\'edvel. Cue o projeto Tachyon, um Sistema de Arquivos Distribu\'eddos baseado em mem\'f3ria de alta velocidade que vem com spark. Voc\'ea pode usar o Tachyon para salvar e ler RDDs atrav\'e9s do SparkContexts de maneira eficiente...\par
O n\'edvel de armazenamento experimental OFF_HEAP tamb\'e9m pode ser usado para persistir RDDs da mesma forma que voc\'ea faria no disco ou na RAM do cluster do Spark. Existem alguns par\'e2metros chave de configura\'e7\'e3o com os quais voc\'ea deve estar familiarizado. O Spark.rdd.compress decide se os RDDs serializados tamb\'e9m devem ou n\'e3o ser compactados.\par
spark.shuffle.consolidateFiles consolida os arquivos intermedi\'e1rios gerados durante um shuffle, criando menos arquivos maiores em vez de muitos pequenos, potencialmente melhorando E / S de disco. Os documentos sugerem configurar isso para true nos sistemas de arquivos ext4 ou xfs. No ext3 isso pode degradar o desempenho em m\'e1quinas com mais de 8 n\'facleos...\par
\b spark.shuffle.spill limita a quantidade de mem\'f3ria usada durante as redu\'e7\'f5es ao derramar dados para disco. \b0 O limite de derramamento \'e9 especificado por spark.shuffle.memoryFraction. Voc\'ea tamb\'e9m pode Defina se o derramamento ser\'e1 ou n\'e3o comprimido. \b spark.storage.memoryFraction \'e9 quanto armazenamento pode ser dedicado \'e0 persist\'eancia na mem\'f3ria. \b0 spark.storage.unrollFraction \'e9 dedicado \b\'e0 mem\'f3ria para "desenrolar" dados serializados, como RDDs persistentes, pois eles s\'e3o armazenados como um grande matriz de bytes. \b0 Tendo completado esta li\'e7\'e3o, voc\'ea deve ser capaz de Entenda como e quando armazenar os RDDs em cache entender os n\'edveis de armazenamento e seus usos, otimize o uso de mem\'f3ria com op\'e7\'f5es de serializa\'e7\'e3o e compartilhe RDDs com o Tachyon. Prossiga para o exerc\'edcio 4 e a pr\'f3xima li\'e7\'e3o.\par
Desenvolvendo e testando\par
Desenvolvendo e Testando Este curso foi desenvolvido em colabora\'e7\'e3o com MetiStream e IBM Analytics. Depois de completar esta li\'e7\'e3o, voc\'ea deve estar capaz de usar o sbt para construir projetos Spark, usar o Eclipse e o IntelliJ for Spark development, unidade teste seus projetos do Spark e gerencie depend\'eancias\b . Sbt \'e9 a ferramenta mais popular para Scala. \b0 Foi constru\'eddo na interface \b REPL \b0 que permite voc\'ea construir e executar a partir do \b shell. \b0\'c9 simples de usar, mas poderoso e extens\'edvel. Tem plugins para o Eclipse e suporte direto no IDE do IntelliJ Se voc\'ea j\'e1 est\'e1 usando ou apenas prefere a familiaridade, voc\'ea tamb\'e9m pode usar o Maven, \b mas n\'e3o \'e9 t\'e3o poderoso ou personaliz\'e1vel\b0 . Aqui est\'e1 um arquivo b\'e1sico de compila\'e7\'e3o sbt. Com o SBT, voc\'ea tamb\'e9m pode criar constru\'e7\'f5es diretamente do console. Por exemplo, renomeando seu projeto atual. \b Na verdade, a sbt pode construir e rodar sem qualquer arquivos de configura\'e7\'e3o em tudo.\b0  Ele encontrar\'e1 automaticamente os arquivos de origem e biblioteca usando um estrutura de diret\'f3rios. Visite a p\'e1gina do projeto sbt e os tutoriais para mais informa\'e7\'f5es. Voc\'ea pode usar o plug-in sbt do Eclipse para gerar os arquivos para um projeto do Eclipse. Basta adicionar esta linha ao arquivo plugins.sbt do seu projeto. Ent\'e3o, a partir do terminal, no diret\'f3rio raiz do seu projeto, execute sbt eclipse. Agora voc\'ea pode importar o projeto de dentro do Eclipse. Isso precisa ser executado novamente toda vez que a compila\'e7\'e3o for alterada. Veja a p\'e1gina do github para o plugin para mais informa\'e7\'f5es. \b O IntelliJ tem uma integra\'e7\'e3o muito mais limpa com o sbt...\par
Suporta totalmente arquivos de compila\'e7\'e3o sbt sem necessidade de convers\'f5es. O IntelliJ possui um console Scala integrado, ele suporta teste e depura\'e7\'e3o de scala. \b0 Analisaremos alguns pontos para come\'e7ar a testar a unidade. Isole suas opera\'e7\'f5es de RDD. As transforma\'e7\'f5es para um determinado RDD devem ser colocadas em seu pr\'f3prio objeto ou classe. Voc\'ea quer testar o c\'f3digo que \'e9 realmente usado em sua aplica\'e7\'e3o. Aproveite as ferramentas de teste padr\'e3o da unidade, como escalar. \b H\'e1 tamb\'e9m o pacote de teste de teste de Spark muito \'fatil que vem com classe auxiliar para facilitar o teste. \b0 Aqui \'e9 parte de uma compila\'e7\'e3o sbt que inclui escalar e testar a base de spark. Aqui est\'e1 um exemplo de teste unit\'e1rio de uma contagem de palavras. N\'f3s temos nossa entrada de teste e os resultados esperados. Ent\'e3o n\'f3s corremos uma contagem de palavras na entrada. Realisticamente a l\'f3gica da contagem de palavras estaria em uma classe ou objeto em outro lugar. Ent\'e3o n\'f3s corremos assertResults para verificar se o valor esperado corresponde \'e0 sa\'edda. Aqui est\'e1 outro teste\b . Mais uma vez, este \'e9 apenas um exemplo inventado para fins de demonstra\'e7\'e3o. assertResult testa que dividir a entrada fornece a sequ\'eancia esperada. Mas neste caso o teste falhar\'e1, pois nossa string de entrada n\'e3o possui espa\'e7os. Um TestFailedException ser\'e1 lan\'e7ado, mostrando os resultados esperados e reais do teste...\par
\b0 Quaisquer bibliotecas adicionais no seu projeto devem ser distribu\'eddas aos trabalhadores. Ao usar o \b script spark-submit, use o sinalizador jars\b0 . Voc\'ea pode referenciar frascos de muitos fontes, incluindo \b HTTP, FTP e HDFS \b0 A pr\'e1tica comum \'e9 agrupar tudo Um grande jarro. Isso \'e9 facilitado com sbt. basta adicionar sbt-assembly para o seu arquivo de plugins. Em seguida, execute o assembly sbt no diret\'f3rio-raiz do seu projeto. Tendo completado esta li\'e7\'e3o, voc\'ea deve ser capaz de usar o sbt para construir projetos Spark, usar Eclipse e IntelliJ for Spark, teste seus projetos de Spark e gerencie depend\'eancias. Parab\'e9ns pela conclus\'e3o do curso. N\'e3o se esque\'e7a de fazer o exerc\'edcio final e o question\'e1rio do curso e, em seguida, preencha o curso coment\'e1rios. Obrigado.\par
\par
\fs22\par
\par
}
 